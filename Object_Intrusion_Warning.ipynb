{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n",
    "import cv2\n",
    "import numpy as np\n",
    "from imutils.video import VideoStream\n",
    "import random as rd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First let set some parameter for path files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please down load the weights file and config file from `https://github.com/kiyoshiiriemon/yolov4_darknet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_weights = \"./yolov4.weights\"\n",
    "path_to_config = \"./yolov4.cfg\"\n",
    "path_to_classname = \"./classnames.txt\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intrusion Warning with Objects detection\n",
    "Using yolo version 4 with pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloDetect():\n",
    "    def __init__(self, detect_class=[\"person\"], img_size=(416, 416), zoom=1, only_detect_object=False):\n",
    "        # Parameters\n",
    "        self.weights_file = path_to_weights\n",
    "        self.config_file = path_to_config\n",
    "        self.classes_file = path_to_classname\n",
    "        self.conf_threshold = 0.5\n",
    "        self.nms_threshold = 0.4\n",
    "        self.detect_class = detect_class\n",
    "        self.scale = 1/255\n",
    "        self.only_detect_object = only_detect_object\n",
    "        self.img_size = img_size\n",
    "        self.zoom = zoom\n",
    "        self.net = cv2.dnn.readNetFromDarknet('yolov4.cfg', 'yolov4.weights')\n",
    "        self.model = cv2.dnn_DetectionModel(self.net)\n",
    "        self.centroid_list = []\n",
    "        self.classes = None\n",
    "        self.dict_color = {}\n",
    "        self.classese_position = {}\n",
    "        self.read_class_file()\n",
    "\n",
    "    # Check whether points inside drew polygon or not \n",
    "    def isInsidePolygon(self, points):\n",
    "        polygon = Polygon(points)\n",
    "        for centroid in self.centroid_list:\n",
    "            centroid = Point(centroid)\n",
    "            if (polygon.contains(centroid)): return True\n",
    "        return False\n",
    "    \n",
    "    # Check wheter detected objects inside other objects or not\n",
    "    def isInsideObjects(self, objects):\n",
    "        for target_obs in objects:\n",
    "            if target_obs not in self.classese_position.keys(): continue\n",
    "            for tbox in self.classese_position[target_obs]:\n",
    "                for centroid in self.centroid_list:\n",
    "                    x, y, w, h = tbox\n",
    "                    if centroid[0]>=x and centroid[0]<=x+w and centroid[1]>=y and centroid[1]<=y+h:\n",
    "                        return True\n",
    "        return False \n",
    "\n",
    "    # Spride out all possible classname from Yolov4 pretrain\n",
    "    def read_class_file(self):\n",
    "        with open(self.classes_file, 'r') as f:\n",
    "            self.classes = f.read().splitlines()\n",
    "        for value in self.classes:\n",
    "            self.dict_color[value]=(rd.randint(0,255), rd.randint(0,255), rd.randint(0,255))\n",
    "\n",
    "    # Set alert when condition is satisfied\n",
    "    def alert(self, img):\n",
    "        cv2.putText(img, \"ALARM!!!!\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        return img\n",
    "    \n",
    "    # Calculate the centeroid of each object\n",
    "    def getCentroid(self, frame, classname, x, y, w_plus, h_plus, color=(0,255,0)):\n",
    "        if classname not in self.detect_class: return frame\n",
    "        centroid = ((x + w_plus) // 2, (y + h_plus) // 2)\n",
    "        cv2.circle(frame, centroid, 5, color, -1)\n",
    "        self.centroid_list.append(centroid)\n",
    "        return frame\n",
    "    \n",
    "    # draw shape for each detected object\n",
    "    def draw_prediction(self, frame, box, classId, score):\n",
    "        if score<self.conf_threshold: return frame\n",
    "        x, y, w, h = box\n",
    "        cv2.rectangle(frame, (x, y), ((x + w), (y + h)), color=self.dict_color[self.classes[classId]], thickness=2)\n",
    "        text = '%s: %.2f' % (self.classes[classId], score)\n",
    "        cv2.putText(frame, text, (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 1, color=self.dict_color[self.classes[classId]], thickness=2)\n",
    "        frame = self.getCentroid(frame, self.classes[classId], x, y, (x+w), (y+h), color=self.dict_color[self.classes[classId]])\n",
    "        return frame\n",
    "    \n",
    "    # Return result after checking\n",
    "    def detect_intrusion_customPolygon(self, frame, points):\n",
    "        if self.isInsidePolygon(points): return self.alert(cv2.resize(frame, (int(frame.shape[1]*self.zoom), int(frame.shape[0]*self.zoom))))\n",
    "        else: return cv2.resize(frame, (int(frame.shape[1]*self.zoom), int(frame.shape[0]*self.zoom)))\n",
    "    \n",
    "    # Return result after checking\n",
    "    def detect_instrusion_objects(self, frame, objects):\n",
    "        if self.isInsideObjects(objects): return self.alert(cv2.resize(frame, (int(frame.shape[1]*self.zoom), int(frame.shape[0]*self.zoom))))\n",
    "        else: return cv2.resize(frame, (int(frame.shape[1]*self.zoom), int(frame.shape[0]*self.zoom)))\n",
    "    \n",
    "    # detect out all the possible ojects in frame\n",
    "    def detect_object(self, frame):\n",
    "        self.classese_position = {}\n",
    "        self.model.setInputParams(scale=self.scale, size=self.img_size, swapRB=True)\n",
    "        classIds, scores, boxes = self.model.detect(frame, confThreshold=self.conf_threshold, nmsThreshold=self.nms_threshold)\n",
    "        for (classId, score, box) in zip(classIds, scores, boxes):\n",
    "            if self.only_detect_object and 'all' not in self.detect_class and self.classes[classId] not in self.detect_class: continue\n",
    "            frame = self.draw_prediction(frame, box, classId, score)\n",
    "            try: self.classese_position[self.classesId].append(box)\n",
    "            except: self.classese_position[self.classes[classId]]=[box]\n",
    "        return frame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reparing main class for model detection, next is several principal functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructor first model\n",
    "model = YoloDetect()\n",
    "\n",
    "# Check whetehr user use mouse for drawing polygon\n",
    "def handle_left_click(event, x, y, flags, points):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        points.append([x, y])\n",
    "\n",
    "# Connect all points to a polygon\n",
    "def draw_polygon (frame, points):\n",
    "    for point in points:\n",
    "        cv2.circle(frame, (point[0], point[1]), 5, (0,0,255), -1)\n",
    "    cv2.polylines(frame, [np.int32(points)], False, (255,0, 0), thickness=2)\n",
    "    return frame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up camera (or input) for model detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OpenStreamCamera(points, targets_class=['person'], objects_class=['polygon'], path='stream', fps=30):\n",
    "    model = YoloDetect(detect_class=targets_class, zoom=1.5)\n",
    "    if path == 'stream': video = VideoStream(src=0).start()\n",
    "    else: video = cv2.VideoCapture(path)\n",
    "    detect = False \n",
    "    while True:\n",
    "        frame = video.read()\n",
    "        # Flip mirror camera\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        key = cv2.waitKey(fps)\n",
    "        draw_polygon(frame, points)\n",
    "        if detect:\n",
    "            frame = model.detect_object(frame)\n",
    "            if objects_class==['polygon']:\n",
    "                frame = model.detect_intrusion_customPolygon(frame, points)\n",
    "            else: frame = model.detect_instrusion_objects(frame, objects_class)\n",
    "        cv2.imshow('Frame', frame)\n",
    "        cv2.setMouseCallback('Frame', handle_left_click, points)\n",
    "        # Press S for breaking procedure\n",
    "        if key==ord('s'): break\n",
    "        # Press Q for starting procedure\n",
    "        elif key == ord('q'):\n",
    "            if len(points)!=0: points.append(points[0])\n",
    "            detect = True\n",
    "    video.stop()\n",
    "    cv2.destroyAllWindows() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `points`: the points in current polygon\n",
    "- `targets_class`: the class that we would focus on\n",
    "- `objects_class`: the class that we would define approaching with `targets_class` or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread WebcamVideoStream:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\APP\\Python\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\APP\\Python\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\APP\\Python\\lib\\site-packages\\imutils\\video\\webcamvideostream.py\", line 34, in update\n",
      "    (self.grabbed, self.frame) = self.stream.read()\n",
      "cv2.error: bad allocation\n",
      "Exception in thread WebcamVideoStream:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\APP\\Python\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\APP\\Python\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\APP\\Python\\lib\\site-packages\\imutils\\video\\webcamvideostream.py\", line 34, in update\n",
      "    (self.grabbed, self.frame) = self.stream.read()\n",
      "cv2.error: bad allocation\n",
      "Exception in thread WebcamVideoStream:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\APP\\Python\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\APP\\Python\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\APP\\Python\\lib\\site-packages\\imutils\\video\\webcamvideostream.py\", line 34, in update\n",
      "    (self.grabbed, self.frame) = self.stream.read()\n",
      "cv2.error: bad allocation\n"
     ]
    }
   ],
   "source": [
    "OpenStreamCamera([], targets_class=['cell phone'], objects_class=['person'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "92ea70cb9331c87a6e87e6ba829f55a3cff66e051583a0c31932cac77bd3dc7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
